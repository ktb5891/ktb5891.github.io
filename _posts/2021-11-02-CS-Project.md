---
layout: post
toc: true
title: "서울 도심권 요식업 상권분석"
categories: project
tags: [Global IT 인재교육원, python, jupyter notebook, machine learning, Sufil]
author:
  - Kwak Tae Beom
---

# Seoul Downtown Area Catering Commercial Sphere Analysis

## 1. 서론

### 1-1. 프로젝트 필요성 및 목적

2019년 12월 중국 우한에서 처음 발생한‘코로나바이러스 감염증-19(이하 코로나)’는 새로운 유형의 바이러스이다. 코로나는 2020년 1월부터 전 세계로 퍼져나갔다. 세계보건기구(WHO)는 2020년 1월, 국제적 공중보건 비상사태를 선포하였고 2월부터 위험도를 ‘매우 높음’으로 격상하였다. 이후 현재까지 코로나는 변이를 통해 지속적인 감염 전파가 이루어지고 있다. 

세계는 코로나라는 초유의 사태를 맞아 격변의 소용돌이 속에 있다. 각국의 봉쇄조치(lock-down) 등으로 세계 경제는 대공황 이후 가장 심각한 충격에 빠졌으며, 경제·사회적 구조도 빠르게 변화하고 있다. 특히 코로나 이전(2018년도 4분기)과 이후(2020년도 4분기)를 비교했을 때, 외식산업 경기전망지수는 대폭 하락하고 있음을 [그림 Ⅰ-1]을 통해 확인할 수 있다.

![image01](https://github.com/ktb5891/ktb5891.github.io/blob/main/img/CS_Project/image01.png?raw=true){: width="800"}
*[그림 Ⅰ-1] 국가통계포털 외식산업경기전망지수*

2020년 6월, 대한민국 정부는 각종 거리두기 명칭을‘사회적 거리두기’로 통일하고 1~3단계로 나누어 방역조치를 실행했다. 이후 1~4단계로 세분화하고 지자체 자율권을 강화하였다.

![image02](https://github.com/ktb5891/ktb5891.github.io/blob/main/img/CS_Project/image02.png?raw=true){: width="800"}
*[그림 Ⅰ-2] 사회적 거리두기 주요 방역수칙*

사회적 거리두기가 장기화하면서 사업체 및 모임시설은 인원제한 및 운영시간에 대한 제약으로 종사자의 피해가 확대되고 있다. 특히 소상공인의 폐업철거비 지원 신청률이 작년 대비 올해 2배가량 증가하였으며 피해가 크다는 것을 알 수 있다. 

특히 요식업에 종사하는 소상공인의 피해가 크다. 서울시 우리 마을 상권분석 사이트의 개폐업수(률) 데이터에 따르면 코로나 이전(2018년도 4분기)과 코로나 이후(2020년도 4분기)의 개폐업률을 비교했을 때, 코로나 이후 폐업률이 상승한 것을 알 수 있다. 특히 관광업이 활성화되어 있는 서울 도심권 3개 구(용산구, 종로구, 중구)에서 높은 수준의 폐업률을 확인할 수 있다. 

![image03](https://github.com/ktb5891/ktb5891.github.io/blob/main/img/CS_Project/image03.png?raw=true){: width="800"}
*<표 Ⅰ-1> 서울시 구별 외식업 개폐업수(률) (단위 : %)*

본 프로젝트는 서울시를 기준으로 구별 상권 분석을 진행하여 요식업에 종사하는 소상공인에서 업종별 사업 입지를 추천하려 한다. 이 때, 폐업률이 높은 3개의 구를 예시로 상권 분석을 진행한다. 

빅데이터 분석을 통해 상권분석 및 추천 입지를 예측하는 것은 다음과 같은 의의가 있다. 첫째, 코로나의 영향으로 침체된 경제 회복이 가능하다. 둘째, 소상공인이 폐업으로 인한 경제적∙정신적 손실을 줄일 수 있다. 셋째, 업종별 추천 입지를 통해 폐업률을 최소화 할 수 있다.

본 프로젝트는 서울시를 기준으로 구별 상권 분석을 진행하여 요식업에 종사하는 소상공인에서 업종별 사업 입지를 추천하려 한다. 이 때, 폐업률이 높은 3개의 구를 예시로 상권 분석을 진행한다. 

빅데이터 분석을 통해 상권분석 및 추천 입지를 예측하는 것은 다음과 같은 의의가 있다. 첫째, 코로나의 영향으로 침체된 경제 회복이 가능하다. 둘째, 소상공인이 폐업으로 인한 경제적∙정신적 손실을 줄일 수 있다. 셋째, 업종별 추천 입지를 통해 폐업률을 최소화 할 수 있다.

### 1-2. 프로젝트 방법 및 프로젝트 추진 절차

#### 머신러닝(Machine Learning) 분석 방법론

상권 분석을 위해서는 기계 스스로 데이터를 기반으로 패턴을 학습하고 결과를 예측하는 머신러닝 방법론을 사용해야 한다. 머신러닝은 알고리즘에 주입하는 훈련 데이터인 레이블(Label)의 포함 여부에 따라 지도 학습(supervised learning)과 비지도 학습(unsupervised learning)으로 나뉜다. 본 프로젝트에서는 `비지도 학습`의 일종으로 `sklearn`의 `Kmeans` 라이브러리를 사용한`‘군집화’`방법론을 사용한다. 이를 통해 해당 지역에 영향을 미치는 변수를 추출한다. 이후 추출된 변수를 고려하여 업종별 입지를 추천하는 방식으로 프로젝트를 진행한다.

#### 프로젝트 추진 절차

본 프로젝트는 [그림 Ⅰ-3] <프로젝트 추진 절차>에 제시한 바와 같이 진행하였다. 프로젝트의 효율적인 진행을 위해 프로젝트 간 분야를 분장하여 단계적 절차 없이 포괄적으로 수행하고 프로젝트 결과를 종합하였으며, 예측 모델을 제시하였다.

![image04](https://github.com/ktb5891/ktb5891.github.io/blob/main/img/CS_Project/image04.png?raw=true){: width="800"}
*[그림 Ⅰ-3] 프로젝트 추진 절차*

## 2. 데이터 수집

### 2-1. 데이터 수집 범위

코로나 19 사태의 지속으로 기존상권 및 새로운 상권이 악화하고 특히 서울 도심의 경기가 많이 침체한 상황이다. 상권분석을 위해서는 많은 변수가 고려되어야 함에 따라 공공데이터가 많이 존재하는 서울특별시를 지역으로 선정한다. 서울특별시에서의 공시지가, 인구수, 유동인구, 매출 데이터를 사용하여 군집화를 통한 업종별 상권분석을 시행하고자 한다. 서울특별시 행정구역별로 지역을 나누고 같은 구 내에서도 동별로 임대료 및 인구수 등이 다르다는 것을 고려하여 행정구역별(25개 구), 동별로 구분한 상권분석을 진행하고자 한다.

![image05](https://github.com/ktb5891/ktb5891.github.io/blob/main/img/CS_Project/image05.png?raw=true){: width="800"}
*[그림 Ⅱ-1] 서울시 행정구역별 지도*

상권분석을 위한 자료를 수집하기 위해 인구수 데이터를 공공데이터 포털, 서울 열린 데이터 광장 포털에서 2021년 1월~3월(1분기)의 임대료, 유동인구(지하철 승하차) 자료를 수집하고, 개인정보를 포함하기 때문에 공공데이터 포털에서는 얻을 수 없는 매출데이터 얻고자 서울특별시 빅 데이터 캠퍼스에 직접 방문하여 신한카드에서 제공하는 업종별 소비데이터를 매출데이터로 활용하였다.

### 2-2. 데이터 수집

#### 유동인구

서울 열린 데이터 광장 포털에서 2021년 1월~3월의 지하철 호선별 역별 승하차 인원 변수들을 추출하여 역별 총 승하차 인원수를 산출하였다.

![image06](https://github.com/ktb5891/ktb5891.github.io/blob/main/img/CS_Project/image06.png?raw=true){: width="800"}
*[그림 II-2] 2021년 서울시 지하철 노선별 역별 승하차 인원 데이터*

#### 총 인구수

서울 열린 데이터 광장 포털에서 2021년 행정구역별 주민등록인구 수를 산출하였다.

![image07](https://github.com/ktb5891/ktb5891.github.io/blob/main/img/CS_Project/image07.png?raw=true){: width="800"}
*[그림 II-3] 2021년 서울시 주민등록인구(구별) 통계 데이터*

#### 상권 업종

공공 데이터 포털에서 2021년 상권 종류와 상권 코드 및 상권 데이터를 활용하였다. 그중에서도 요식업에 속하는 상권 업종 중분류 코드가 ‘Q’인 데이터만 추출하여 활용하였다.

![image08](https://github.com/ktb5891/ktb5891.github.io/blob/main/img/CS_Project/image08.png?raw=true){: width="800"}
*[그림 II-4] 2021년 서울특별시 소상공인시장진흥공단 상권정보 데이터*

#### 임대료

우리 마을가게 상권분석 서비스 포털에서 행정구역별 동별 전 분기 임대료 평균 데이터를 추출하였다. 그 중 ‘2021년 1분기 전체’ 데이터를 사용하였다.

![image09](https://github.com/ktb5891/ktb5891.github.io/blob/main/img/CS_Project/image09.png?raw=true){: width="800"}
*[그림 II-5] 2021년 1분기 서울시 임대료 데이터*

#### 매출

##### 카드 소비 데이터

서울시민의 업종별 카드소비 패턴 데이터에서 업종코드별 블록코드(지역)별 카드이용내역(금액)을 사용하였다.

![image11](https://github.com/ktb5891/ktb5891.github.io/blob/main/img/CS_Project/image11.png?raw=true){: width="800"}
*[그림 II-6] 서울 시민의 업종별 카드소비 패턴 데이터*

##### 업종 코드 데이터

서울시민의 업종별 카드소비 패턴 데이터에서 업종코드별 블록코드(지역)별 카드이용내역(금액)을 사용하였다.

![image12](https://github.com/ktb5891/ktb5891.github.io/blob/main/img/CS_Project/image12.png?raw=true){: width="800"}
*[그림 II-7] 신한카드 내국인 63업종 코드 데이터*

##### 블록 코드 데이터

업종별 카드 소비 패턴 데이터에서 블록 코드를 확인하기 위해 사용하였다.

![image13](https://github.com/ktb5891/ktb5891.github.io/blob/main/img/CS_Project/image13.png?raw=true){: width="800"}
*[그림 II-8] 블록영역 정보 데이터*

## 데이터 전처리

`데이터 전처리(Preprocessing)`란 수집 데이터 중 분석 결과나 모델 성능에 악영향을 미칠 수 있는 값을 가공하는 작업을 의미한다. 즉, 원활한 데이터 분석을 위해 데이터 자체 혹은 수집 과정에서 발생한 오류를 데이터 전처리 과정을 통해 정제하는 것이다. 데이터 전처리는 이상치를 확인 및 제거하고, 결측치를 대체하는 `‘데이터 클리닝(Cleaning)’`, 다양한 로그 파일과 데이터베이스를 일관성 있는 데이터 형태로 변환하는 `데이터 통합(Integration)`, `정규화(Normalization)`, `집합화(Aggregation)`, `요약(Summarization)` 등의 과정을 통해 데이터의 형태를 변환하고 방대한 데이터를 축소하는 `데이터 변환(Transformation)`과 `데이터 축소(Reduction)`의 과정을 거친다. 이를 바탕으로 필요한 데이터를 추출하여 데이터를 분석한다.

### 데이터 클리닝

원본 데이터는 공공 데이터 포털 및 빅데이터 캠퍼스에서 제공하는 가공된 데이터이므로 이상치가 존재하지 않아 데이터 클리닝 과정은 생략하였다. 

상권업종 데이터의 경우, 데이터 크기로 인한 하드웨어적인 문제로 'Excel'의 함수를 사용하여 상권 업종대분류 코드의 ‘Q’만을 추출한 후 ‘Python' 프로그래밍 언어를 사용하여 ’Jupyter Notebook'에서 이하의 데이터 전처리 과정을 진행하였다.

### 데이터 통합

본 프로젝트에서는 2021년을 기준으로 하였으며 서울시 주민등록인구 통계 데이터에서 행정구역별 ‘총인구’, 지역별 평균 임대료 데이터에서 ‘21년도_전체’, 서울시 지하철 호선별 역별 승하차 인원 정보 데이터에서 ‘역명’, ‘승차총승객수’, ‘하차총승객수’, 상공인 시장 진흥공단 서울특별시 상가(상권)정보 데이터에서 ‘상권업종’, ‘상권 업종 중분류 코드’, ‘시군구 코드’, ‘행정동 코드’, ‘도로명주소’, ‘위도’, ‘경도’ 필드를 ‘Excel'의 필터 기능과 ’Python'의 Pandas 모듈의 함수를 사용하여 데이터를 취합했다. 또한 빅데이터 캠퍼스에서 제공하는 서울시민의 업종별 카드 소비 패턴 데이터에서 ‘AMT_CORR(카드이용금액계)’를 활용하기 위해 업종, 블록(지역) 구분을 위해 신한카드_내국인_63 업종_코드 데이터에서 ‘CB_UPJONG_CD', 서울시 블록 단위 지역 경계도 데이터에서 ’BLCK_CD(블록_코드)‘ 필드를 추출하고 위 데이터 또한 빅 데이터이므로 ’Excel', 'Jupyter Notebook'을 활용하여 데이터를 취합하였다. 빅 데이터 캠퍼스에서 제공하는 데이터는 원 데이터 형태로 반출할 수 없어서 총인구, 유동인구, 업종, 임대료 데이터를 빅데이터 캠퍼스 내부 컴퓨터에서 반입 후 행정구역별 군집화 결과를 지도에 시각화한 후 HTML 형태로 반출하였고 매출 데이터를 포함하지 않은 반입데이터에 군집화 결과인 클러스터 값을 병합한 후 반출하였다.

### 데이터 변환 및 축소

#### 필요 라이브러리 및 함수 호출

Python을 사용하여 분석을 용이하게 하기 위해  ‘`Pandas`', '`Numpy`' 라이브러리를 사용하였고, 전처리된 데이터를 분석하는 여러 기법 중 군집화를 위한 '`sklearn`'의 '`StandardScaler`', '`K-Means`', '`PCA`', '`Silhouette_score`', '`Silhouette_samples`' 라이브러리를 사용하였다. 분석한 결과를 시각화하기 위해 그래프와 지도를 불러올 수 있는 `matplotlib`, `Folium` 라이브러리를 사용하여, 총 9개의 라이브러리를 불러(import)왔다.

![image14](https://github.com/ktb5891/ktb5891.github.io/blob/main/img/CS_Project/image14.png?raw=true){: width="800"}
*[그림 Ⅲ-1] Python 라이브러리 사용*

#### 데이터 탐색

정제한 데이터를 데이터 분석 구현 환경에 가져온다. 한글을 Python에서 구현하기 위해 CP949 코드를 이용하여 인코딩하고 ‘df’이라는 변수명으로 저장한다.

요식업 소상공인 업종별 입지 분석을 위해 필요한 변수(Feature)를 이전 데이터 전처리 과정에서 Excel과 Python을 이용하여 정제하였다. 따라서, 데이터 분석 단계에서는 추가 데이터 처리 없이 분석을 시행한다.

군집화 대상인 변수의 데이터 형태를 파악하고 실제 군집화에 필요한 변수인 ‘시군구 코드’, ‘행정동 코드’, ‘임대료’, ‘동별 인구수’, ‘지하철 승하차 인구수’, ‘지하철역명’, ‘상권 업종 중분류 코드’, ‘매출액’을 추출하여 각 변수명을 ‘Gu_code’, ‘Dong_code’, ‘rent_21_total’, ‘total_pop’, ‘total_station’, ‘station_name’, ‘com_sort_code’, ‘profit_21’로 리스트를 만든다.

특히, 구 코드, 행정동 코드, 상권 업종 중 분류 코드의 경우, 명목형 변수로 다르다라는 개념을 나타내어 군집화를 실행해야 하므로 [그림Ⅲ-4]와 같이 단어 집합의 크기를 벡터의 차원으로 하고, 표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, 다른 인덱스에는 0을 부여하는 단어의 벡터 표현 방식인 원-핫 인코딩(One-Hot Encoding) 추출하여 표현한다.

```python
dum_df = pd.get_dummies(df_zero)
```

리스트화한 변수를 군집화를 위해 데이터 프레임 ‘df’로, ‘행정동(dong_name)’, ‘위도(lat)’, ‘경도(lng)’ 변수를 추가하여 지도 시각화를 위한 데이터 프레임인 ‘df2’로 저장한다.

#### Feature Scaling

각 변수의 값의 편차가 크기 때문에 큰 값을 지닌 변수가 군집(cluster)을 형성할 때 더 큰 영향을 줄 수 있다. 이를 해결하기 위해 Standard_Scaler 라이브러리를 이용한 피처 스케일링(Feature Scaling, 각 변수의 단위를 0~1 사이, 혹은 상대적 값을 표현할 수 있는 수치로 변경하는 것)을 시행한다.

```python
val_scaled = StandardScaler().fit_transform(val)
```

#### PCA 차원 축소

다차원 변수(5개)를 2개의 변수로 줄여서 데이터를 좀 더 잘 설명할 수 있는 잠재적인 요소를 추출하고 직관적인 데이터 해석을 하기 위해 앞에서 호출한 PCA 라이브러리를 사용하여 차원축소를 진행하였다.

## 데이터 분석
